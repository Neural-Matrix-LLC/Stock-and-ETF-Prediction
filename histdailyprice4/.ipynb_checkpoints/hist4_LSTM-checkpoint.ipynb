{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9826b412-d227-40c4-94d1-a7e631522ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce059f59-ec68-452f-8bc1-9a78b7537bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import mysql.connector\n",
    "\n",
    "HOST=\"143.244.188.157\"\n",
    "PORT=\"3306\"\n",
    "USER=\"patrick-finProj\"\n",
    "PASSWORD=\"Pat#21$rick\"\n",
    "\n",
    "try: \n",
    "    conn = mysql.connector.connect(\n",
    "        host=HOST,\n",
    "        port=PORT,\n",
    "        user=USER,\n",
    "        password=PASSWORD,\n",
    "        database=\"GlobalMarketData\"\n",
    "    )\n",
    "    query = f\"SELECT * FROM histdailyprice4;\"\n",
    "    histdailyprice4 = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    conn.close()\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e72ad559-dbb9-43d0-b2ce-29de72c55a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>AdjClose</th>\n",
       "      <th>ActualPercent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>111.94</td>\n",
       "      <td>104.87</td>\n",
       "      <td>112.50</td>\n",
       "      <td>101.69</td>\n",
       "      <td>4783900</td>\n",
       "      <td>0.855709</td>\n",
       "      <td>8.433090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>AMAT</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>126.50</td>\n",
       "      <td>128.40</td>\n",
       "      <td>128.40</td>\n",
       "      <td>125.30</td>\n",
       "      <td>3589100</td>\n",
       "      <td>23.712400</td>\n",
       "      <td>4.901190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>AMD</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>31.00</td>\n",
       "      <td>29.94</td>\n",
       "      <td>31.19</td>\n",
       "      <td>29.38</td>\n",
       "      <td>3921600</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>5.645160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>BA</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>40.19</td>\n",
       "      <td>41.63</td>\n",
       "      <td>41.69</td>\n",
       "      <td>39.81</td>\n",
       "      <td>2638200</td>\n",
       "      <td>25.897600</td>\n",
       "      <td>0.149291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>BAC</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>48.44</td>\n",
       "      <td>50.25</td>\n",
       "      <td>50.25</td>\n",
       "      <td>48.00</td>\n",
       "      <td>6852900</td>\n",
       "      <td>13.043600</td>\n",
       "      <td>5.945500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Symbol Exchange   Close    Open    High     Low   Volume  \\\n",
       "Date                                                                  \n",
       "2000-01-03   AAPL   NASDAQ  111.94  104.87  112.50  101.69  4783900   \n",
       "2000-01-03   AMAT   NASDAQ  126.50  128.40  128.40  125.30  3589100   \n",
       "2000-01-03    AMD   NASDAQ   31.00   29.94   31.19   29.38  3921600   \n",
       "2000-01-03     BA     NYSE   40.19   41.63   41.69   39.81  2638200   \n",
       "2000-01-03    BAC     NYSE   48.44   50.25   50.25   48.00  6852900   \n",
       "\n",
       "             AdjClose  ActualPercent  \n",
       "Date                                  \n",
       "2000-01-03   0.855709       8.433090  \n",
       "2000-01-03  23.712400       4.901190  \n",
       "2000-01-03  15.500000       5.645160  \n",
       "2000-01-03  25.897600       0.149291  \n",
       "2000-01-03  13.043600       5.945500  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = histdailyprice4.copy()\n",
    "df.Date = pd.to_datetime(df.Date)\n",
    "df.set_index('Date', inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c99012ab-197e-4e7d-9bad-56bbd9177996",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [\"Close\", \"Open\", \"High\", \"Low\", \"Volume\", \"AdjClose\", \"ActualPercent\"]\n",
    "\n",
    "# Split data into training set and test set\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "\n",
    "# Scale feature MinMax\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(df_train.loc[:,train_cols].values)\n",
    "X_test = min_max_scaler.transform(df_test.loc[:,train_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8fe91e3-4007-4ceb-a308-4eac19aac90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "params = {\n",
    "    \"BATCH_SIZE\": 50,\n",
    "    \"EPOCHS\": 50,\n",
    "    \"LR\": 0.00010000,\n",
    "    \"TIME_STEPS\": 60\n",
    "    }\n",
    "\n",
    "OUTPUT_PATH = '/outputs'\n",
    "TIME_STEPS = params['TIME_STEPS']\n",
    "BATCH_SIZE = params['BATCH_SIZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c542e39-48a9-4850-9016-99b2fecb9339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of inputs 412505\n",
      "length of time-series - inputs (412505, 60, 7)\n",
      "length of time-series - outputs (412505,)\n",
      "Batch trimmed size (412500, 60, 7) (412500,)\n"
     ]
    }
   ],
   "source": [
    "def trim_dataset(mat, batch_size):\n",
    "    \"\"\"Trims dataset to a size that's divisible by BATCH_SIZE\"\"\"\n",
    "    \n",
    "    no_of_rows_drop = mat.shape[0] % batch_size\n",
    "\n",
    "    if no_of_rows_drop > 0:\n",
    "        return mat[:-no_of_rows_drop]\n",
    "    else:\n",
    "        return mat\n",
    "\n",
    "def build_timeseries(mat, y_col_index):\n",
    "    \"\"\"Transform data into time series format\"\"\"\n",
    "    \n",
    "    dim_0 = mat.shape[0] - TIME_STEPS\n",
    "    dim_1 = mat.shape[1]\n",
    "\n",
    "    X = np.zeros((dim_0, TIME_STEPS, dim_1))\n",
    "    y = np.zeros((dim_0,))\n",
    "\n",
    "    print(\"Length of inputs\", dim_0)\n",
    "\n",
    "    for i in range(dim_0):\n",
    "        X[i] = mat[i:TIME_STEPS+i]\n",
    "        y[i] = mat[TIME_STEPS+i, y_col_index]\n",
    "\n",
    "    print(\"length of time-series - inputs\", X.shape)\n",
    "    print(\"length of time-series - outputs\", y.shape)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_t, y_t = build_timeseries(X_train, 3)\n",
    "X_t = trim_dataset(X_t, BATCH_SIZE)\n",
    "y_t = trim_dataset(y_t, BATCH_SIZE)\n",
    "print(\"Batch trimmed size\", X_t.shape, y_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e57f343b-ef01-472e-a1b6-0d0113067bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"Customized loss function that takes into account directional loss.\n",
    "    \n",
    "    ARGS:\n",
    "    y_true: tensor of true price\n",
    "    y_pred: tensor of predicted price\n",
    "    \n",
    "    RETURN:\n",
    "    custom loss output\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #the \"next day's price\" of tensor\n",
    "        y_true_next = y_true[1:]\n",
    "        y_pred_next = y_pred[1:]\n",
    "\n",
    "        #the \"today's price\" of tensor\n",
    "        y_true_tdy = y_true[:-1]\n",
    "        y_pred_tdy = y_pred[:-1]\n",
    "\n",
    "        #substract to get up/down movement of the two tensors\n",
    "        y_true_diff = tf.subtract(y_true_next, y_true_tdy)\n",
    "        y_pred_diff = tf.subtract(y_pred_next, y_pred_tdy)\n",
    "\n",
    "        #create a standard tensor with zero value for comparison\n",
    "        standard = tf.zeros_like(y_pred_diff)\n",
    "\n",
    "        #compare with the standard; if true, UP; else DOWN\n",
    "        y_true_move = tf.greater_equal(y_true_diff, standard)\n",
    "        y_pred_move = tf.greater_equal(y_pred_diff, standard)\n",
    "        y_true_move = tf.reshape(y_true_move, [-1])\n",
    "        y_pred_move = tf.reshape(y_pred_move, [-1])\n",
    "\n",
    "\n",
    "        #find indices where the directions are not the same\n",
    "        condition = tf.not_equal(y_true_move, y_pred_move)\n",
    "        indices = tf.where(condition)\n",
    "\n",
    "        #move one position later\n",
    "        ones = tf.ones_like(indices)\n",
    "        indices = tf.add(indices, ones)\n",
    "        indices = K.cast(indices, dtype='int32')\n",
    "\n",
    "\n",
    "        #create a tensor to store directional loss and put it into custom loss output\n",
    "        direction_loss = tf.Variable(tf.ones_like(y_pred), dtype='float32')\n",
    "        updates = K.cast(tf.ones_like(indices), dtype='float32')\n",
    "        alpha = 1000\n",
    "        direction_loss = tf.scatter_nd_update(direction_loss, indices, alpha*updates)\n",
    "\n",
    "        custom_loss = K.mean(tf.multiply(K.square(y_true - y_pred), direction_loss), axis=-1)\n",
    "\n",
    "        return custom_loss\n",
    "    except Exception as e:\n",
    "        logging.error(\"Exception occurred at get_price_movement()\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fd6a48c2-dcdd-4af5-913a-58d418f6bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model():\n",
    "    \"\"\"Build LSTM model\"\"\"\n",
    "      \n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(100, batch_input_shape=(BATCH_SIZE, TIME_STEPS, X_t.shape[2]),\n",
    "                        dropout=0.0, recurrent_dropout=0.0,\n",
    "                        stateful=True, return_sequences=True,\n",
    "                        kernel_initializer='random_uniform'))\n",
    "\n",
    "    lstm_model.add(LSTM(60, dropout=0.0))\n",
    "    \n",
    "    lstm_model.add(Dense(20,activation='relu'))\n",
    "    lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "    #Compile the model\n",
    "    optimizer = optimizers.Adam(lr=params[\"LR\"])\n",
    "    lstm_model.compile(loss=custom_loss, optimizer=optimizer)\n",
    "  \n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39f20370-f64e-4509-8698-63644da05a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of inputs 45781\n",
      "length of time-series - inputs (45781, 60, 7)\n",
      "length of time-series - outputs (45781,)\n",
      "Test size (22875, 60, 7) (22875,) (22875, 60, 7) (22875,)\n"
     ]
    }
   ],
   "source": [
    "'''Split test data into validation set and test set'''\n",
    "X_temp, y_temp = build_timeseries(X_test, 3)\n",
    "X_val, X_test_t = np.array_split(trim_dataset(X_temp, BATCH_SIZE), 2)\n",
    "y_val, y_test_t = np.array_split(trim_dataset(y_temp, BATCH_SIZE), 2)\n",
    "print(\"Test size\", X_test_t.shape, y_test_t.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe168815-e631-4ba2-9262-f500236874cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(X_t).sum())\n",
    "print(np.isnan(y_t).sum())\n",
    "print(np.isnan(X_val).sum())\n",
    "print(np.isnan(y_val).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b72a63f9-217b-4f21-9d26-6ce8d3ea34b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (50, 60, 100)             43200     \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (50, 60)                  38640     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (50, 20)                  1220      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (50, 1)                   21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83,081\n",
      "Trainable params: 83,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception occurred at get_price_movement()\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/__autograph_generated_filemuw9nt4z.py\", line 31, in tf__custom_loss\n",
      "    direction_loss = ag__.converted_call(ag__.ld(tf).scatter_nd_update, (ag__.ld(direction_loss), ag__.ld(indices), (ag__.ld(alpha) * ag__.ld(updates))), None, fscope)\n",
      "AttributeError: module 'tensorflow' has no attribute 'scatter_nd_update'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/simplypatrickg/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/simplypatrickg/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/simplypatrickg/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/simplypatrickg/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"/Users/simplypatrickg/.local/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/simplypatrickg/.local/lib/python3.8/site-packages/keras/losses.py\", line 142, in __call__\n        return losses_utils.compute_weighted_loss(\n    File \"/Users/simplypatrickg/.local/lib/python3.8/site-packages/keras/utils/losses_utils.py\", line 309, in compute_weighted_loss\n        losses = tf.convert_to_tensor(losses)\n\n    ValueError: None values not supported.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_92610/3601374244.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_lstm_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m history_lstm = lstm_model.fit(X_t, y_t, epochs=params[\"EPOCHS\"], verbose=1, batch_size=BATCH_SIZE,\n\u001b[0m\u001b[1;32m      7\u001b[0m                   shuffle=False, validation_data=(trim_dataset(X_val, BATCH_SIZE),\n\u001b[1;32m      8\u001b[0m                   trim_dataset(y_val, BATCH_SIZE)), callbacks=[mcp])\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/simplypatrickg/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/simplypatrickg/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/simplypatrickg/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/simplypatrickg/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"/Users/simplypatrickg/.local/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/simplypatrickg/.local/lib/python3.8/site-packages/keras/losses.py\", line 142, in __call__\n        return losses_utils.compute_weighted_loss(\n    File \"/Users/simplypatrickg/.local/lib/python3.8/site-packages/keras/utils/losses_utils.py\", line 309, in compute_weighted_loss\n        losses = tf.convert_to_tensor(losses)\n\n    ValueError: None values not supported.\n"
     ]
    }
   ],
   "source": [
    "lstm_model = create_lstm_model()\n",
    "print(lstm_model.summary())\n",
    "\n",
    "mcp = ModelCheckpoint(os.path.join(OUTPUT_PATH, \"best_lstm_model.h5\"), monitor='val_loss', verbose=2, save_best_only=True, save_weights_only=False, mode='min', save_freq=1)\n",
    "\n",
    "history_lstm = lstm_model.fit(X_t, y_t, epochs=params[\"EPOCHS\"], verbose=1, batch_size=BATCH_SIZE,\n",
    "                  shuffle=False, validation_data=(trim_dataset(X_val, BATCH_SIZE),\n",
    "                  trim_dataset(y_val, BATCH_SIZE)), callbacks=[mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888948e8-86a1-4252-8e13-cdb4bb8d371e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95f5e0-917d-4ebd-96f5-794b88b394da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e1040-436a-4010-8db8-3612e5afe8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
