{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9a4131-8f86-4101-8cd9-2b79edf0f07d",
   "metadata": {},
   "source": [
    "# Ensemble Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5f3b1d-6a40-42bf-8ae8-10bfcec1aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da12ded-9502-452e-9982-02ebbd3dc1cc",
   "metadata": {},
   "source": [
    "# List of Stocks and ETFs\n",
    "Provided by Thomas Choi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8aa776c-9fc6-4010-afac-7fd8544c03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list = pd.read_csv(\"../stocks_and_etfs/stock_list.csv\")\n",
    "etf_list = pd.read_csv(\"../stocks_and_etfs/etf_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30f1e6d-3f0f-4ba8-9e1c-b485fce703dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCX\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Choose a random stock\n",
    "#stock_symbol = random.choice(stock_list.iloc[:,0])\n",
    "stock_symbol = \"FCX\"\n",
    "print(stock_symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b738c1-e67d-47ab-8276-d4d5332c169f",
   "metadata": {},
   "source": [
    "## MySQL connection\n",
    "Choosing one stock from SQL query to reduce query time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c28066-acb4-455d-aaec-5c32318adb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import mysql.connector\n",
    "\n",
    "HOST=\"143.244.188.157\"\n",
    "PORT=\"3306\"\n",
    "USER=\"patrick-finProj\"\n",
    "PASSWORD=\"Pat#21$rick\"\n",
    "\n",
    "try: \n",
    "    conn = mysql.connector.connect(\n",
    "        host=HOST,\n",
    "        port=PORT,\n",
    "        user=USER,\n",
    "        password=PASSWORD,\n",
    "        database=\"GlobalMarketData\"\n",
    "    )\n",
    "    query = f\"SELECT Date, Exchange, Close, Open, High, Low, Volume from histdailyprice3 WHERE Symbol='{stock_symbol}';\"\n",
    "    histdailyprice3 = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    conn.close()\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554beeed-0b93-4984-aa6f-9b32f1de6877",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "282f3ce2-766a-4804-b635-7ef45b9e967a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-01-01</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>7.875</td>\n",
       "      <td>7.875</td>\n",
       "      <td>7.875</td>\n",
       "      <td>7.875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-01-02</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>7.875</td>\n",
       "      <td>8.000</td>\n",
       "      <td>7.875</td>\n",
       "      <td>7.970</td>\n",
       "      <td>279300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-01-05</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>7.970</td>\n",
       "      <td>8.000</td>\n",
       "      <td>7.845</td>\n",
       "      <td>7.875</td>\n",
       "      <td>455300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-01-06</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>7.845</td>\n",
       "      <td>7.875</td>\n",
       "      <td>7.750</td>\n",
       "      <td>7.750</td>\n",
       "      <td>476200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-01-07</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>7.720</td>\n",
       "      <td>7.875</td>\n",
       "      <td>7.685</td>\n",
       "      <td>7.845</td>\n",
       "      <td>464100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Exchange  Close   Open   High    Low  Volume\n",
       "0  1998-01-01     NYSE  7.875  7.875  7.875  7.875       0\n",
       "1  1998-01-02     NYSE  7.875  8.000  7.875  7.970  279300\n",
       "2  1998-01-05     NYSE  7.970  8.000  7.845  7.875  455300\n",
       "3  1998-01-06     NYSE  7.845  7.875  7.750  7.750  476200\n",
       "4  1998-01-07     NYSE  7.720  7.875  7.685  7.845  464100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = histdailyprice3.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2471242-157d-45af-ac7b-028881b98260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NYSE'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get exchange\n",
    "df.Exchange.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3f4c06-54bb-418d-96cc-517ec2ec035a",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35805828-3607-472a-b8ac-6c30a206e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# normalize data\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaled_data = scaler.fit_transform(df[\"Close\"].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d98c6f-36b8-43e2-b102-4a9978aa8505",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a38a28c0-a1da-4a69-a055-551416dd5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step=1):\n",
    "    x_data, y_data = [], []\n",
    "    \n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        x_data.append(dataset[i:(i+time_step), 0])\n",
    "        y_data.append(dataset[i + time_step, 0])\n",
    "    return np.array(x_data), np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "762477bf-0833-4227-a27a-ee41153eec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing train and test data\n",
    "training_size = int(len(scaled_data)*0.65)\n",
    "test_size = len(scaled_data)-training_size\n",
    "train_data, test_data = scaled_data[0:training_size,:], scaled_data[training_size:len(scaled_data),:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68a2f60d-ccf2-4112-ad17-cc8839b52bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking data for past 100 days for next prediction\n",
    "time_step = 100\n",
    "\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, ytest = create_dataset(test_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3302e3e3-4496-4571-92f6-d6122c4ac54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e445b467-8979-4b94-961f-0fe943a56079",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f95d3954-33f9-4695-a768-68d602c43e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout,LSTM\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(layers.LSTM(units = hp.Choice('layer1_units', [10,20,30,40,50,60,70,80,90,100]),return_sequences=True,input_shape=(100,1)))\n",
    "    \n",
    "    for i in range(hp.Int('num_layers', 2, 15)):                        \n",
    "        model.add(layers.LSTM(units =  hp.Int('units' + str(i), min_value=10, max_value=150, step=10), return_sequences=True))\n",
    "    \n",
    "    model.add(LSTM(units = hp.Choice('last_lstm_units', [50, 100, 150])))\n",
    "    model.add(Dropout(rate = hp.Choice('rate', [0.3, 0.4, 0.5, 0.6, 0.7])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam' )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00ae026-5b5f-48ab-92ca-96b9dc514191",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7a43c-81c7-438d-9654-45eb77f479a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 15:23:01.314669: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "layer1_units (Choice)\n",
      "{'default': 10, 'conditions': [], 'values': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100], 'ordered': True}\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 15, 'step': 1, 'sampling': None}\n",
      "units0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 150, 'step': 10, 'sampling': None}\n",
      "units1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 150, 'step': 10, 'sampling': None}\n",
      "last_lstm_units (Choice)\n",
      "{'default': 50, 'conditions': [], 'values': [50, 100, 150], 'ordered': True}\n",
      "rate (Choice)\n",
      "{'default': 0.3, 'conditions': [], 'values': [0.3, 0.4, 0.5, 0.6, 0.7], 'ordered': True}\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "layer1_units      |80                |?                 \n",
      "num_layers        |14                |?                 \n",
      "units0            |60                |?                 \n",
      "units1            |60                |?                 \n",
      "last_lstm_units   |100               |?                 \n",
      "rate              |0.6               |?                 \n",
      "\n",
      "Epoch 1/5\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0335"
     ]
    }
   ],
   "source": [
    "import keras_tuner\n",
    "from tensorflow.keras import layers\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials= 5,\n",
    "    executions_per_trial=3,\n",
    "    directory='tuner', project_name = f'{stock_symbol}')\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs= 5,\n",
    "             validation_data=(X_test, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbfc935-4f65-413b-aeff-c701de27a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894611c8-d8c6-4be6-b527-8828e0a5a804",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "**EarlyStoping:** It will stop the traning if score of model didn't increase. This prevent model from overfitting. We are to set max in 10 epoches if it didn't increase then we will stop the training <br>\n",
    "**ReduceLROnPlateau:** Use for reduce the learning rate. In 3 steps the score didn't increase we will reduce the learning rate to improve the training <br>\n",
    "**ModelCheckpoint:** Use for save model only when the score increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b4a201-c8f2-4c2d-9673-79eeeb05400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('weights_best.hdf5', verbose=2, save_best_only=True, \n",
    "                    save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57699d35-5c71-4659-ae71-74bba81e7cd6",
   "metadata": {},
   "source": [
    "# Compile LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a485c1-3e95-4595-99a4-8bee08498f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b4c84c-fa48-4e9d-b6c8-3f3322048ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "#model.fit(x_train, y_train, epochs=25, batch_size=32, callbacks=callbacks)\n",
    "model_history = model.fit(X_train,y_train, epochs=100, validation_data=(X_test,ytest), callbacks=callbacks)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca7daa7-f415-4a31-959d-757b019fea3a",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d9931a-269a-436d-8860-2a7bae239ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model_history.history['loss']\n",
    "validation_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(17, 7));\n",
    "plt.plot(loss, label='Training Loss');\n",
    "plt.plot(validation_loss, label='Validation Loss');\n",
    "plt.legend(loc='upper left');\n",
    "plt.title('Loss : Training Vs Validation ');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacdd9ea-819e-4a19-aef7-cef789751ae8",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6a8d4-cde4-4278-96b9-13fe2090e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b747ef2-c45e-4fb5-95ab-8d012820d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict=scaler.inverse_transform(train_predict)\n",
    "test_predict=scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65951a3a-d79b-4fad-b449-c1b177c733c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back=100\n",
    "trainPredictPlot = np.empty_like(df)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(train_predict) + look_back, :] = train_predict\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(df)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(train_predict) + (look_back*2) + 1: len(df) - 1, :] = test_predict\n",
    "\n",
    "plt.plot(df[\"Close\"])\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.title('Train Vs Test predictions');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2162a09e-283a-4ead-8fc5-1006ed27f89d",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f9a4db-8106-47c1-8d39-2b8c5536cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"Train RMSE: \", math.sqrt(mean_squared_error(y_train,train_predict)))\n",
    "print(\"Test RMSE: \", math.sqrt(mean_squared_error(ytest,test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d816e-3d88-4882-9a7d-a811ffdffe66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
