{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9717d467",
   "metadata": {},
   "source": [
    "# Stock Price Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23fa5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4db457a",
   "metadata": {},
   "source": [
    "# List of Stocks and ETFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "547abe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list = pd.read_csv(\"../stocks_and_etfs/stock_list.csv\")\n",
    "etf_list = pd.read_csv(\"../stocks_and_etfs/etf_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5b0a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCX\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Choose a random stock\n",
    "#stock_symbol = random.choice(stock_list.iloc[:,0])\n",
    "stock_symbol = \"FCX\"\n",
    "print(stock_symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c527f59",
   "metadata": {},
   "source": [
    "## MySQL connection\n",
    "Choosing one stock from SQL query to reduce query time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6525148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import mysql.connector\n",
    "\n",
    "HOST=\"143.244.188.157\"\n",
    "PORT=\"3306\"\n",
    "USER=\"patrick-finProj\"\n",
    "PASSWORD=\"Pat#21$rick\"\n",
    "\n",
    "try: \n",
    "    conn = mysql.connector.connect(\n",
    "        host=HOST,\n",
    "        port=PORT,\n",
    "        user=USER,\n",
    "        password=PASSWORD,\n",
    "        database=\"GlobalMarketData\"\n",
    "    )\n",
    "    query = f\"SELECT Date, Close, Open, High, Low, Volume from histdailyprice3 WHERE Symbol='{stock_symbol}';\"\n",
    "    histdailyprice3 = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    conn.close()\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a899299",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0eac57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-01-01</td>\n",
       "      <td>7.875</td>\n",
       "      <td>7.875</td>\n",
       "      <td>7.875</td>\n",
       "      <td>7.875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-01-02</td>\n",
       "      <td>7.875</td>\n",
       "      <td>8.000</td>\n",
       "      <td>7.875</td>\n",
       "      <td>7.970</td>\n",
       "      <td>279300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-01-05</td>\n",
       "      <td>7.970</td>\n",
       "      <td>8.000</td>\n",
       "      <td>7.845</td>\n",
       "      <td>7.875</td>\n",
       "      <td>455300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-01-06</td>\n",
       "      <td>7.845</td>\n",
       "      <td>7.875</td>\n",
       "      <td>7.750</td>\n",
       "      <td>7.750</td>\n",
       "      <td>476200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-01-07</td>\n",
       "      <td>7.720</td>\n",
       "      <td>7.875</td>\n",
       "      <td>7.685</td>\n",
       "      <td>7.845</td>\n",
       "      <td>464100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Close   Open   High    Low  Volume\n",
       "0  1998-01-01  7.875  7.875  7.875  7.875       0\n",
       "1  1998-01-02  7.875  8.000  7.875  7.970  279300\n",
       "2  1998-01-05  7.970  8.000  7.845  7.875  455300\n",
       "3  1998-01-06  7.845  7.875  7.750  7.750  476200\n",
       "4  1998-01-07  7.720  7.875  7.685  7.845  464100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = histdailyprice3.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e328fc",
   "metadata": {},
   "source": [
    "# Test Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7057e5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set size - 5559\n",
      "Test data set size - 618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_cols = [\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]\n",
    "df_train, df_test = train_test_split(df, train_size=0.9, test_size=0.1, shuffle=False)\n",
    "print(\"Training data set size -\", len(df_train))\n",
    "print(\"Test data set size -\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affcaf65",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11c93bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x = df_train.loc[:,train_cols].values\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_train = min_max_scaler.fit_transform(x)\n",
    "x_test = min_max_scaler.transform(df_test.loc[:,train_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c641cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Set environment parameters'''\n",
    "#Show warning & error\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1daf841",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4db29504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters for model\n",
    "params = {\n",
    "    \"BATCH_SIZE\": 50,\n",
    "    \"EPOCHS\": 50,\n",
    "    \"LR\": 0.00010000,\n",
    "    \"TIME_STEPS\": 60\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a30b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = params['TIME_STEPS']\n",
    "BATCH_SIZE = params['BATCH_SIZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "325e6570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_time(text, stime):\n",
    "    seconds = (time.time()-stime)\n",
    "    print(text, seconds//60,\"minutes : \", np.round(seconds%60),\"seconds\")\n",
    "\n",
    "def trim_dataset(mat, batch_size):\n",
    "    \n",
    "    #trims dataset to a size that's divisible by BATCH_SIZE\n",
    "    no_of_rows_drop = mat.shape[0] % batch_size\n",
    "\n",
    "    if no_of_rows_drop > 0:\n",
    "        return mat[:-no_of_rows_drop]\n",
    "    else:\n",
    "        return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17e6eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_timeseries(mat, y_col_index):\n",
    "    \n",
    "    dim_0 = mat.shape[0] - TIME_STEPS\n",
    "    dim_1 = mat.shape[1]\n",
    "\n",
    "    x = np.zeros((dim_0, TIME_STEPS, dim_1))\n",
    "    y = np.zeros((dim_0,))\n",
    "\n",
    "    print(\"Length of inputs\", dim_0)\n",
    "\n",
    "    for i in range(dim_0):\n",
    "        x[i] = mat[i:TIME_STEPS+i]\n",
    "        y[i] = mat[TIME_STEPS+i, y_col_index]\n",
    "\n",
    "    print(\"length of time-series - inputs\", x.shape)\n",
    "    print(\"length of time-series - outputs\", y.shape)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcf59159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of inputs 5499\n",
      "length of time-series - inputs (5499, 60, 5)\n",
      "length of time-series - outputs (5499,)\n",
      "Batch trimmed size (5450, 60, 5) (5450,)\n"
     ]
    }
   ],
   "source": [
    "x_t, y_t = build_timeseries(x_train, 3)\n",
    "x_t = trim_dataset(x_t, BATCH_SIZE)\n",
    "y_t = trim_dataset(y_t, BATCH_SIZE)\n",
    "print(\"Batch trimmed size\", x_t.shape, y_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6deed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "    #extract the \"next day's price\" of tensor\n",
    "    y_true_next = y_true[1:]\n",
    "    y_pred_next = y_pred[1:]\n",
    "    \n",
    "    #extract the \"today's price\" of tensor\n",
    "    y_true_tdy = y_true[:-1]\n",
    "    y_pred_tdy = y_pred[:-1]\n",
    "    \n",
    "    print('Shape of y_pred_back -', y_pred_tdy.get_shape())\n",
    "    \n",
    "    #substract to get up/down movement of the two tensors\n",
    "    y_true_diff = tf.subtract(y_true_next, y_true_tdy)\n",
    "    y_pred_diff = tf.subtract(y_pred_next, y_pred_tdy)\n",
    "        \n",
    "    #create a standard tensor with zero value for comparison\n",
    "    standard = tf.zeros_like(y_pred_diff)\n",
    "    \n",
    "    #compare with the standard; if true, UP; else DOWN\n",
    "    y_true_move = tf.greater_equal(y_true_diff, standard)\n",
    "    y_pred_move = tf.greater_equal(y_pred_diff, standard)\n",
    "    y_true_move = tf.reshape(y_true_move, [-1])\n",
    "    y_pred_move = tf.reshape(y_pred_move, [-1])\n",
    "    \n",
    "\n",
    "    #find indices where the directions are not the same\n",
    "    condition = tf.not_equal(y_true_move, y_pred_move)\n",
    "    indices = tf.where(condition)\n",
    "\n",
    "    #move one position later\n",
    "    ones = tf.ones_like(indices)\n",
    "    indices = tf.add(indices, ones)\n",
    "    indices = K.cast(indices, dtype='int32')\n",
    "    \n",
    "    \n",
    "    #create a tensor to store directional loss and put it into custom loss output\n",
    "    direction_loss = tf.Variable(tf.ones_like(y_pred), dtype='float32')\n",
    "    updates = K.cast(tf.ones_like(indices), dtype='float32')\n",
    "    alpha = 1000\n",
    "    direction_loss = tf.scatter_nd_update(direction_loss, indices, alpha*updates)\n",
    "    \n",
    "    custom_loss = K.mean(tf.multiply(K.square(y_true - y_pred), direction_loss), axis=-1)\n",
    "    \n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f636a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model():\n",
    "      \n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(100, batch_input_shape=(BATCH_SIZE, TIME_STEPS, x_t.shape[2]),\n",
    "                        dropout=0.0, recurrent_dropout=0.0,\n",
    "                        stateful=True, return_sequences=True,\n",
    "                        kernel_initializer='random_uniform'))\n",
    "    #lstm_model.add(Dropout(0.4))\n",
    "\n",
    "    lstm_model.add(LSTM(60, dropout=0.0))\n",
    "    #lstm_model.add(Dropout(0.4))\n",
    "    \n",
    "    lstm_model.add(Dense(20,activation='relu'))\n",
    "    lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "    #compile the model\n",
    "    optimizer = optimizers.Adam(lr=params[\"LR\"])\n",
    "    lstm_model.compile(loss=custom_loss, optimizer=optimizer)\n",
    "  \n",
    "    return lstm_model\n",
    "\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9faf867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "\n",
    "x_temp, y_temp = build_timeseries(x_test, 3)\n",
    "x_val, x_test_t = np.array_split(trim_dataset(x_temp, BATCH_SIZE), 2)\n",
    "y_val, y_test_t = np.array_split(trim_dataset(y_temp, BATCH_SIZE), 2)\n",
    "print(\"Test size\", x_test_t.shape, y_test_t.shape, x_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "is_update_model = False\n",
    "\n",
    "\n",
    "if model is None or is_update_model:\n",
    "      \n",
    "    print(\"Building model...\")\n",
    "\n",
    "    lstm_model = create_lstm_model()\n",
    "    print(lstm_model.summary())\n",
    "    \n",
    "    mcp = ModelCheckpoint(os.path.join(OUTPUT_PATH, \"best_lstm_model.h5\"), monitor='val_loss', verbose=2, save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "\n",
    "    '''Step 14 - Fit model'''\n",
    "    history_lstm = lstm_model.fit(x_t, y_t, epochs=params[\"EPOCHS\"], verbose=1, batch_size=BATCH_SIZE,\n",
    "                      shuffle=False, validation_data=(trim_dataset(x_val, BATCH_SIZE),\n",
    "                      trim_dataset(y_val, BATCH_SIZE)), callbacks=[mcp])\n",
    "\n",
    "    print(\"saving model...\")\n",
    "  \n",
    "    pickle.dump(lstm_model, open(\"lstm_model\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a4bcea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
